{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习\n",
    "\n",
    "# 一、概述\n",
    "\n",
    "### 1. 什么是机器学习？\n",
    "\n",
    "- 人工智能：通过人工的方法，实现或者近似实现某些需要人类智能处理的问题，都可以称为人工智能。\n",
    "- 机器学习：一个计算机程序在完成任务T之后，获得经验E，而该经验的效果可以通过P得以表现，如果随着T的增加，借助P来表现的E也可以同步增进，则称这样的程序为机器学习系统。\n",
    "- 特点：自我完善、自我修正、自我增强。\n",
    "\n",
    "### 2. 为什么需要机器学习？\n",
    "\n",
    "1. 简化或者替代人工方式的模式识别，易于系统的开发维护和升级换代。\n",
    "2. 对于那些算法过于复杂，或者没有明确解法的问题，机器学习系统具有得天独厚的优势。\n",
    "3. 借鉴机器学习的过程，反向推理出隐藏在业务数据背后的规则——数据挖掘。\n",
    "\n",
    "### 3. 机器学习的类型\n",
    "\n",
    "1. **有监督学习**、**无监督学习**、**半监督学习**和**强化学习**\n",
    "2. **批量学习**和**增量学习**\n",
    "3. **基于实例**的学习和**基于模型**的学习\n",
    "\n",
    "### 4. 机器学习的流程\n",
    "\n",
    "1. 数据\n",
    "    - 数据采集\n",
    "    - 数据清洗\n",
    "2. 机器学习\n",
    "    - 数据预处理  \n",
    "    - 选择模型\n",
    "    - 训练模型\n",
    "    - 验证模型\n",
    "3. 业务\n",
    "    - 使用模型\n",
    "    - 维护和升级"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、数据预处理\n",
    "\n",
    "- `import sklearn.preprocessing as sp`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 均值移除(标准化) Standardization (or Z-score normalization)\n",
    "\n",
    "- 通过算法调整令样本矩阵中每一列(特征)的平均值为0，标准差为1。这样一来，所有特征对最终模型的预测结果都有接近一致的贡献，模型对每个特征的倾向性更加均衡。\n",
    "    \n",
    ">Standardization (or Z-score normalization) is the process of rescaling the features so that they’ll have the properties of a Gaussian distribution with μ=0 and σ=1 where μ is the mean and σ is the standard deviation from the mean; standard scores (also called z scores) of the samples are calculated as follows:\n",
    "$$z = \\frac{{x - \\mu }}{\\sigma }$$\n",
    "\n",
    "- `sp.scale(原始样本矩阵)` -> 经过均值移除后的样本矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  -1.5  2.  -5.4]\n",
      " [ 0.   4.  -0.3  2.1]\n",
      " [ 1.   3.3 -1.9 -4.3]]\n",
      "Mean: [ 1.33333333  1.93333333 -0.06666667 -2.53333333]\n",
      "S: [1.24721913 2.44449495 1.60069429 3.30689515]\n",
      "手动标准化处理后： [[ 1.33630621 -1.40451644  1.29110641 -0.86687558]\n",
      " [-1.06904497  0.84543708 -0.14577008  1.40111286]\n",
      " [-0.26726124  0.55907936 -1.14533633 -0.53423728]]\n",
      "处理后的每一列均值： [ 5.55111512e-17 -1.11022302e-16 -7.40148683e-17 -7.40148683e-17]\n",
      "处理后的每一列方差： [1. 1. 1. 1.]\n",
      "自动标准化处理后： [[ 1.33630621 -1.40451644  1.29110641 -0.86687558]\n",
      " [-1.06904497  0.84543708 -0.14577008  1.40111286]\n",
      " [-0.26726124  0.55907936 -1.14533633 -0.53423728]]\n",
      "处理后的每一列均值： [ 5.55111512e-17 -1.11022302e-16 -7.40148683e-17 -7.40148683e-17]\n",
      "处理后的每一列方差： [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# std.py\n",
    "import numpy as np\n",
    "import sklearn.preprocessing as sp\n",
    "raw_samples = np.array([\n",
    "    [3, -1.5,  2,   -5.4],\n",
    "    [0,  4,   -0.3,  2.1],\n",
    "    [1,  3.3, -1.9, -4.3]])\n",
    "print(raw_samples)\n",
    "print('Mean:', raw_samples.mean(axis=0))  # 表示沿着行取平均值，得到每一列的均值\n",
    "print('S:', raw_samples.std(axis=0))\n",
    "\n",
    "std_samples = raw_samples.copy()\n",
    "for col in std_samples.T:\n",
    "    col_mean = col.mean()\n",
    "    col_std = col.std()\n",
    "    col -= col_mean\n",
    "    col /= col_std\n",
    "print('手动标准化处理后：', std_samples)\n",
    "print('处理后的每一列均值：', std_samples.mean(axis=0))\n",
    "print('处理后的每一列方差：', std_samples.std(axis=0))\n",
    "\n",
    "std_samples = sp.scale(raw_samples)  # 经过均值移除后的样本矩阵\n",
    "print('自动标准化处理后：', std_samples)\n",
    "print('处理后的每一列均值：', std_samples.mean(axis=0))\n",
    "print('处理后的每一列方差：', std_samples.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 范围缩放 Min-Max scaling\n",
    "\n",
    "- 将样本矩阵每一列的元素经过某种线性变换，使得所有列的元素都处在同样的范围区间内，自行设置min和max。\n",
    "\n",
    "$$kx + b = y \\\\\n",
    "k \\cdot co{l_{\\min }} + b = \\min \\\\\n",
    "k \\cdot co{l_{\\max }} + b = \\max$$\n",
    "\n",
    "$$\n",
    "\\left( {\\begin{array}{*{20}{c}}\n",
    "{co{l_{\\min }}}&1\\\\\n",
    "{co{l_{\\max }}}&1\n",
    "\\end{array}} \\right)\\left( {\\begin{array}{*{20}{c}}\n",
    "k\\\\\n",
    "b\n",
    "\\end{array}} \\right) = \\left( {\\begin{array}{*{20}{c}}\n",
    "{\\min }\\\\\n",
    "{\\max }\n",
    "\\end{array}} \\right)$$\n",
    "\n",
    "                                                      a      x      b\n",
    "                                            = np.linalg.solve(a, b)\n",
    "                                            = np.linalg.lstsq(a, b)[0]\n",
    "\n",
    "- 有时候也把以[0, 1]区间作为目标范围的范围缩放称为\"归一化\"\n",
    "\n",
    ">An alternative approach to Z-score normalization (or standardization) is the so-called Min-Max scaling (often also simply called “normalization” - a common cause for ambiguities).In this approach, the data is scaled to a fixed range usually 0 to 1.The cost of having this bounded range - in contrast to standardization - is that we will end up with smaller standard deviations, which can suppress the effect of outliers. A Min-Max scaling is typically done via the following equation:\n",
    "$${x_i}^\\prime  = \\frac{{{x_i} - \\min (x)}}{{\\max (x) - \\min (x)}}$$\n",
    "\n",
    "- `范围缩放器 = sp.MinMaxScaler(feature_range=(min, max))`\n",
    "\n",
    "- `范围缩放器.fit_transform(原始样本矩阵)` -> 经过范围缩放后的样本矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  -1.5  2.  -5.4]\n",
      " [ 0.   4.  -0.3  2.1]\n",
      " [ 1.   3.3 -1.9 -4.3]]\n",
      "[[ 1.00000000e+00  0.00000000e+00  1.00000000e+00 -1.11022302e-16]\n",
      " [ 0.00000000e+00  1.00000000e+00  4.10256410e-01  1.00000000e+00]\n",
      " [ 3.33333333e-01  8.72727273e-01  5.55111512e-17  1.46666667e-01]]\n",
      "[[1.         0.         1.         0.        ]\n",
      " [0.         1.         0.41025641 1.        ]\n",
      " [0.33333333 0.87272727 0.         0.14666667]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn.preprocessing as sp\n",
    "\n",
    "raw_samples = np.array([\n",
    "    [3, -1.5,  2,   -5.4],\n",
    "    [0,  4,   -0.3,  2.1],\n",
    "    [1,  3.3, -1.9, -4.3]])\n",
    "print(raw_samples)\n",
    "mms_samples = raw_samples.copy()\n",
    "\n",
    "for col in mms_samples.T:\n",
    "    col_min = col.min()\n",
    "    col_max = col.max()\n",
    "    a = np.array([\n",
    "        [col_min, 1],\n",
    "        [col_max, 1]])\n",
    "    b = np.array([0, 1])\n",
    "    x = np.linalg.solve(a, b)\n",
    "    col *= x[0]\n",
    "    col += x[1]\n",
    "print(mms_samples)\n",
    "\n",
    "mms = sp.MinMaxScaler(feature_range=(0, 1))\n",
    "mms_samples = mms.fit_transform(raw_samples)\n",
    "print(mms_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 归一化\n",
    "\n",
    "- 用每个样本各个特征值除以该样本所有特征值绝对值之和，以占比的形式来表现特征。\n",
    "\n",
    "- `sp.normalize(原始样本矩阵, norm='l1')` -> 经过归一化后的样本矩阵\n",
    "    - `l1 - l1范数`，矢量诸元素的绝对值之和\n",
    "    - `l2 - l2范数`，矢量诸元素的(绝对值的)平方之和\n",
    "    - `ln - ln范数`，矢量诸元素的绝对值的n次方之和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  -1.5  2.  -5.4]\n",
      " [ 0.   4.  -0.3  2.1]\n",
      " [ 1.   3.3 -1.9 -4.3]]\n",
      "[[ 0.25210084 -0.12605042  0.16806723 -0.45378151]\n",
      " [ 0.          0.625      -0.046875    0.328125  ]\n",
      " [ 0.0952381   0.31428571 -0.18095238 -0.40952381]]\n",
      "[1. 1. 1.]\n",
      "[[ 0.25210084 -0.12605042  0.16806723 -0.45378151]\n",
      " [ 0.          0.625      -0.046875    0.328125  ]\n",
      " [ 0.0952381   0.31428571 -0.18095238 -0.40952381]]\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn.preprocessing as sp\n",
    "raw_samples = np.array([\n",
    "    [3, -1.5,  2,   -5.4],\n",
    "    [0,  4,   -0.3,  2.1],\n",
    "    [1,  3.3, -1.9, -4.3]])\n",
    "print(raw_samples)\n",
    "\n",
    "# 手动归一\n",
    "nor_samples = raw_samples.copy()\n",
    "for row in nor_samples:\n",
    "    row_absum = abs(row).sum()\n",
    "    row /= row_absum\n",
    "print(nor_samples)\n",
    "print(abs(nor_samples).sum(axis=1))\n",
    "\n",
    "# 自动归一\n",
    "nor_samples = sp.normalize(raw_samples, norm='l1')\n",
    "print(nor_samples)\n",
    "print(abs(nor_samples).sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 二值化\n",
    "\n",
    "- 根据事先给定阈值，将样本矩阵中高于阈值的元素设置为1，否则设置为0，得到一个完全由1和0组成的二值矩阵。\n",
    "\n",
    "- `二值化器 = sp.Binarizer(threshold=阈值)`\n",
    "\n",
    "- `二值化器.transform(原始样本矩阵)` -> 经过二值化后的样本矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  -1.5  2.  -5.4]\n",
      " [ 0.   4.  -0.3  2.1]\n",
      " [ 1.   3.3 -1.9 -4.3]]\n",
      "[[1. 0. 1. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 1. 0. 0.]]\n",
      "[[1. 0. 1. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn.preprocessing as sp\n",
    "\n",
    "raw_samples = np.array([\n",
    "    [3, -1.5,  2,   -5.4],\n",
    "    [0,  4,   -0.3,  2.1],\n",
    "    [1,  3.3, -1.9, -4.3]])\n",
    "print(raw_samples)\n",
    "\n",
    "# 手动二值化\n",
    "bin_samples = raw_samples.copy()\n",
    "bin_samples[bin_samples <= 1.4] = 0\n",
    "bin_samples[bin_samples > 1.4] = 1\n",
    "print(bin_samples)\n",
    "\n",
    "# 自动二值化\n",
    "bin = sp.Binarizer(threshold=1.4)\n",
    "bin_samples = bin.transform(raw_samples)\n",
    "print(bin_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 独热编码\n",
    "\n",
    "- 用一个只包含一个1和若干个0的序列来表达每个特征值的编码方式，借此既保留了样本矩阵的所有细节，同时又得到一个只含有1和0的稀疏矩阵，既可以提高模型的容错性，同时还能节省内存空间。\n",
    "\n",
    "        ----------------------原始矩阵\n",
    "        1        3        2\n",
    "        7        5        4\n",
    "        1        8        6\n",
    "        7        3        9\n",
    "        ----------------------编码字典\n",
    "        1:10   3:100   2:1000\n",
    "        7:01   5:010   4:0100\n",
    "               8:001   6:0010\n",
    "                       9:0001\n",
    "        ----------------------编码后样本矩阵\n",
    "        101001000\n",
    "        010100100\n",
    "        100010010\n",
    "        011000001\n",
    "\n",
    "- `独热编码器 = sp.OneHotEncoder(sparse=是否紧缩(缺省True), dtype=类型)`\n",
    "\n",
    "- `独热编码器.fit_transform(原始样本矩阵)` -> 经过独热编码后的样本矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw array:\n",
      " [[1 3 2]\n",
      " [7 5 4]\n",
      " [1 8 6]\n",
      " [7 3 9]]\n",
      "手动编码：\n",
      " [[1 0 1 0 0 1 0 0 0]\n",
      " [0 1 0 1 0 0 1 0 0]\n",
      " [1 0 0 0 1 0 0 1 0]\n",
      " [0 1 1 0 0 0 0 0 1]]\n",
      "自动编码：\n",
      " [[1 0 1 0 0 1 0 0 0]\n",
      " [0 1 0 1 0 0 1 0 0]\n",
      " [1 0 0 0 1 0 0 1 0]\n",
      " [0 1 1 0 0 0 0 0 1]]\n",
      "自动编码：\n",
      "   (0, 0)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 6)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 7)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 8)\t1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn.preprocessing as sp\n",
    "raw_samples = np.array([\n",
    "    [1, 3, 2],\n",
    "    [7, 5, 4],\n",
    "    [1, 8, 6],\n",
    "    [7, 3, 9]])\n",
    "print('Raw array:\\n', raw_samples)\n",
    "\n",
    "# 建立编码字典列表\n",
    "code_tables = []\n",
    "for col in raw_samples.T:\n",
    "    # 针对一列的编码字典\n",
    "    code_table = {}\n",
    "    for val in col:\n",
    "        code_table[val] = None\n",
    "    code_tables.append(code_table)\n",
    "    \n",
    "# 为编码字典列表中每个编码字典添加值\n",
    "for code_table in code_tables:\n",
    "    size = len(code_table)\n",
    "    for one, key in enumerate(sorted(code_table.keys())):\n",
    "        code_table[key] = np.zeros(shape=size, dtype=int)\n",
    "        code_table[key][one] = 1\n",
    "        \n",
    "# 根据编码字典表对原始样本矩阵做独热编码\n",
    "ohe_samples = []\n",
    "for raw_sample in raw_samples:\n",
    "    ohe_sample = np.array([], dtype=int)\n",
    "    for i, key in enumerate(raw_sample):\n",
    "        ohe_sample = np.hstack((ohe_sample, code_tables[i][key]))\n",
    "    ohe_samples.append(ohe_sample)\n",
    "ohe_samples = np.array(ohe_samples)\n",
    "print('手动编码：\\n', ohe_samples)\n",
    "\n",
    "# 自动独热编码\n",
    "ohe = sp.OneHotEncoder(sparse=False, dtype=int, categories='auto')\n",
    "ohe_samples = ohe.fit_transform(raw_samples)\n",
    "print('自动编码：\\n', ohe_samples)\n",
    "# 自动独热编码(紧缩模式)\n",
    "ohe = sp.OneHotEncoder(dtype=int, categories='auto')\n",
    "ohe_samples = ohe.fit_transform(raw_samples)\n",
    "print('自动编码：\\n', ohe_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 标签编码\n",
    "\n",
    "- 文本形式的特征值->数值形式的特征值，其编码数值源于标签字符串的字典排序，与标签本身的含义无关\n",
    "\n",
    "        职位    车     编码为：\n",
    "        员工  toyota     0\n",
    "        组长  ford       1\n",
    "        经理  audi       2\n",
    "        老板  bmw        3\n",
    "\n",
    "- `标签编码器 = sp.LabelEncoder()`\n",
    "\n",
    "- `标签编码器.fit_transform(原始样本矩阵)` -> 经过标签编码后的样本矩阵\n",
    "\n",
    "- `标签编码器.inverse_transform(经过标签编码后的样本矩阵)` -> 原始样本矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw array:\n",
      " ['audi' 'ford' 'audi' 'toyota' 'ford' 'bmw' 'toyota' 'bmw']\n",
      "Labeled:\n",
      " [0 2 0 3 2 1 3 1]\n",
      "Inverse:\n",
      " ['audi' 'ford' 'audi' 'toyota' 'ford' 'bmw' 'toyota' 'bmw']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn.preprocessing as sp\n",
    "\n",
    "raw_samples = np.array(['audi', 'ford', 'audi', 'toyota', 'ford', 'bmw', 'toyota', 'bmw'])\n",
    "print('Raw array:\\n', raw_samples)\n",
    "\n",
    "lbe = sp.LabelEncoder()\n",
    "lbe_samples = lbe.fit_transform(raw_samples)\n",
    "print('Labeled:\\n', lbe_samples)\n",
    "\n",
    "raw_samples = lbe.inverse_transform(lbe_samples)\n",
    "print('Inverse:\\n', raw_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、机器学习的基本问题\n",
    "\n",
    "1. **回归问题**：由已知的分布于连续域中的输入和输出，通过不断地模型训练，找到输入和输出之间的联系，通常这种联系可以通过一个函数方程被形式化，如：y=w0+w1x+w2x^2...，当提供未知输出的输入时，就可以根据以上函数方程，预测出与之对应的连续域输出。\n",
    "\n",
    "2. **分类问题**：如果将回归问题中的输出从连续域变为离散域，那么该问题就是一个分类问题。\n",
    "\n",
    "3. **聚类问题**：从已知的输入中寻找某种模式，比如相似性，根据该模式将输入划分为不同的集群，并对新的输入应用同样的划分方式，以确定其归属的集群。\n",
    "\n",
    "4. **降维问题**：从大量的特征中选择那些对模型预测最关键的少量特征，以降低输入样本的维度，提高模型的性能。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
